# 02.11:
## Julia: 
### Current goal: evaluate the feasibility of our point 3 (i.e. collecting new data on 2024 using LLMs). Have to check if LLMs can have a ""human"" behaviour.
Tasks done:
- found the paths the most played in Wikispeedia ✔️
- wrote some ideas of prompts ✔️
- tried really hard to find a framework that automatize requests to LLMs ❎

Pbs encountered:
- struggle to download LLM on my machine: quickly reach the limits of my RAM
- don't manage to execute the LLM on my machine once download: docker container which fails

# 04.11:
## Julia: 
### Current goal: evaluate the feasibility of our point 3 (i.e. collecting new data on 2024 using LLMs). Have to check if LLMs can have a ""human"" behaviour.
#### Intermediate goal: make work those bloody LLMs locally
Tasks done:
- achieve several bluescreens ✔️
- tried other methods than transformers to dw models --> fail ❎
- downloaded smaller models ✔️
- still trying to make it run locally ❎
